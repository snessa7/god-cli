# God CLI - Project Summary

## ğŸ¯ What Was Created

A complete Python CLI tool for interacting with your local Ollama instance, with the alias "god" as requested.

## ğŸ“ Project Structure

```
god cli/
â”œâ”€â”€ god_cli.py          # Main CLI application (8.2KB)
â”œâ”€â”€ config_manager.py   # Interactive settings manager (4.5KB)
â”œâ”€â”€ setup.py            # Python package installer (1.7KB)
â”œâ”€â”€ requirements.txt    # Python dependencies (57B)
â”œâ”€â”€ install.sh          # Automated installation script (3.0KB)
â”œâ”€â”€ quick_start.sh      # Quick start without full install (1.7KB)
â”œâ”€â”€ demo.py             # Demo script to showcase features (1.7KB)
â”œâ”€â”€ README.md           # Comprehensive documentation (4.7KB)
â””â”€â”€ PROJECT_SUMMARY.md  # This file
```

## ğŸš€ Quick Start

### Option 1: Quick Start (Recommended for first use)
```bash
./quick_start.sh
```

### Option 2: Direct Usage
```bash
./god_cli.py
```

### Option 3: Full Installation (Creates 'god' alias)
```bash
./install.sh
```

## ğŸ”§ Key Features

- **Interactive Chat**: Type `god` to start chatting with AI models
- **Configurable Settings**: Temperature, tokens, system prompts, etc.
- **Model Management**: List and switch between available models
- **Chat History**: Persistent conversation history
- **Easy Configuration**: JSON-based config file at `~/.god_cli_config.json`
- **Connection Testing**: Built-in connection diagnostics

## ğŸ“‹ Prerequisites

1. **Python 3.7+** installed
2. **Ollama** running locally (`ollama serve`)
3. **At least one model** pulled (e.g., `ollama pull llama2`)

## ğŸ® Usage Examples

### Start Chatting
```bash
god                    # Start interactive chat
god --model llama2     # Use specific model
god --test             # Test connection
```

### Interactive Commands
- `help` - Show available commands
- `models` - List available models
- `config` - Show current settings
- `clear` - Clear screen
- `quit` - Exit chat

### Configuration
```bash
./config_manager.py    # Interactive settings manager
```

## ğŸ”— How the 'god' Alias Works

The `install.sh` script automatically:
1. Installs the Python package
2. Detects your shell (zsh, bash, fish)
3. Adds `alias god='python3 /path/to/god_cli.py'` to your shell profile
4. Makes the alias available after reloading your shell

## ğŸ› ï¸ Customization

### Configuration File Location
`~/.god_cli_config.json`

### Key Settings
- `ollama_url`: Ollama server URL
- `default_model`: Default AI model
- `temperature`: Response randomness (0.0-1.0)
- `max_tokens`: Maximum response length
- `system_prompt`: System message for AI
- `max_history`: Chat history size

## ğŸ§ª Testing

### Test Connection
```bash
./god_cli.py --test
```

### Run Demo
```bash
./demo.py
```

## ğŸ“š Documentation

- **README.md**: Complete user guide and troubleshooting
- **Inline Code**: Well-documented Python code with docstrings
- **Help System**: Built-in help command in the chat interface

## ğŸ‰ What You Can Do Now

1. **Start chatting immediately** with `./god_cli.py`
2. **Install permanently** with `./install.sh` to get the `god` alias
3. **Customize settings** with `./config_manager.py`
4. **Test everything** with `./demo.py`

## ğŸš¨ Troubleshooting

### Common Issues
- **"Cannot connect to Ollama"**: Run `ollama serve`
- **"No models found"**: Run `ollama pull llama2`
- **Permission denied**: Run `chmod +x *.py *.sh`

### Quick Fixes
```bash
# Start Ollama
ollama serve

# Pull a model
ollama pull llama2

# Test connection
./god_cli.py --test
```

---

**ğŸ¯ You now have a fully functional "god" CLI tool for Ollama!**

Type `./quick_start.sh` to begin, or `./install.sh` for permanent installation.
